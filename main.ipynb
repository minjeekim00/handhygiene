{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tqdm/autonotebook/__init__.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, io, shutil\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tensorboardX import SummaryWriter\n",
    "from dataloader.handhygiene import HandHygiene\n",
    "from openpose_transforms import MultiScaleTorsoRandomCrop\n",
    "from spatial_transforms import Compose\n",
    "from spatial_transforms import Normalize\n",
    "from spatial_transforms import Scale\n",
    "from spatial_transforms import CenterCrop\n",
    "from spatial_transforms import RandomHorizontalFlip\n",
    "from spatial_transforms import RandomAffine\n",
    "from spatial_transforms import RandomRotation\n",
    "from spatial_transforms import ColorJitter\n",
    "from spatial_transforms import ToTensor #ExtractSkinColor\n",
    "from temporal_transforms import TemporalRandomChoice\n",
    "from temporal_transforms import TemporalRandomCrop\n",
    "from temporal_transforms import LoopPadding, MirrorPadding, MirrorLoopPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'i3d'\n",
    "batch_size = 16\n",
    "clip_length_in_frames = 16\n",
    "clip_length_aug = clip_length_in_frames/2\n",
    "num_classes = 1\n",
    "\n",
    "#torch.manual_seed(100)\n",
    "data_name = 'anesthesia'\n",
    "dataset_path = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 224\n",
    "mean=[110.63666788, 103.16065604, 96.29023126]\n",
    "std=[38.7568578, 37.88248729, 40.02898126]\n",
    "#mean=[128, 128, 128]\n",
    "#std=[128, 128, 128]\n",
    "\n",
    "scales=np.linspace(1, 1.75, num=1e3)\n",
    "center=((1+1.75)/2)\n",
    "openpose_transform = {\n",
    "    'train':MultiScaleTorsoRandomCrop(scales, sample_size),\n",
    "    'val':MultiScaleTorsoRandomCrop(np.linspace(center, center, num=1), sample_size, centercrop=True)\n",
    "}\n",
    "spatial_transform = {\n",
    "    'train': Compose([Scale(sample_size),\n",
    "                      CenterCrop(sample_size),\n",
    "                      RandomHorizontalFlip(),\n",
    "                      ColorJitter(brightness=0.1),\n",
    "                      RandomAffine(5),\n",
    "                      RandomRotation(2.5),\n",
    "                      ToTensor(1), \n",
    "                      Normalize(mean, std)]),\n",
    "    'val': Compose([Scale(sample_size), \n",
    "                    CenterCrop(sample_size), \n",
    "                    ToTensor(1), \n",
    "                    Normalize(mean, std)])}\n",
    "temporal_transform = {\n",
    "    'train':Compose([ #TemporalRandomCrop(clip_length_aug),\n",
    "                TemporalRandomChoice([\n",
    "                    LoopPadding(clip_length_in_frames),\n",
    "                    MirrorPadding(clip_length_in_frames),\n",
    "                    MirrorLoopPadding(clip_length_in_frames)])]),\n",
    "    'val': LoopPadding(clip_length_in_frames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train':HandHygiene(dataset_path, split='train', \n",
    "                        clip_length_in_frames=clip_length_in_frames, \n",
    "                        spatial_transform=spatial_transform['train'],\n",
    "                        openpose_transform=openpose_transform['train'],\n",
    "                        temporal_transform=temporal_transform['train']\n",
    "                       ),\n",
    "    'val':HandHygiene(dataset_path, split='val',\n",
    "                        clip_length_in_frames=clip_length_in_frames, \n",
    "                        spatial_transform=spatial_transform['val'],\n",
    "                        openpose_transform=openpose_transform['val'],\n",
    "                        temporal_transform=temporal_transform['val']\n",
    "                     ),\n",
    "    'test':HandHygiene(dataset_path, split='test', \n",
    "                        clip_length_in_frames=clip_length_in_frames, \n",
    "                        spatial_transform=spatial_transform['val'],\n",
    "                        openpose_transform=openpose_transform['val'],\n",
    "                        temporal_transform=temporal_transform['val']\n",
    "                      )}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(dataset['train'], batch_size=batch_size, shuffle=True, num_workers=16),\n",
    "    'val': DataLoader(dataset['val'], batch_size=batch_size, shuffle=False, num_workers=16)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phase in ['train', 'val', 'test']:\n",
    "    dataset[phase].__ref__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_models\n",
    "from train import train\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def show_dataset(item): # item: C x D x 244 x 244\n",
    "    rgbs = item[0].transpose(0, 1)\n",
    "    flows = item[1].transpose(0, 1)\n",
    "    n = len(rgbs)\n",
    "    shape = np.asarray(flows[0]).shape\n",
    "    rgb = np.hstack((np.asarray(rgb).transpose(1, 2, 0)+1)/2 for rgb in rgbs)\n",
    "    #gray = np.hstack((np.squeeze(np.asarray(gray))+1)/2 for gray in rgbs)\n",
    "    tmp = np.zeros((shape[1], shape[2], 1))\n",
    "    flow = np.hstack((np.dstack((np.asarray(flow).transpose(1, 2, 0), tmp))+1)/2 for flow in flows)\n",
    "\n",
    "    img = np.vstack((rgb, flow))\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    plt.imshow(img)\n",
    "    #plt.imshow(gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(item[2])\n",
    "\n",
    "i=400\n",
    "phase='train'\n",
    "show_dataset(dataset[phase].__getitem__(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "i3d_rgb, i3d_flow = get_models(num_classes, True, 170, load_pt_weights=True) # unfreeze last mix 170, 152\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    i3d_rgb = nn.DataParallel(i3d_rgb)\n",
    "    i3d_flow = nn.DataParallel(i3d_flow)\n",
    "i3d_rgb.to(device)\n",
    "i3d_flow.to(device)\n",
    "\n",
    "criterion = F.binary_cross_entropy\n",
    "optims={'rgb':None, 'flow':None}\n",
    "schedulers = {'rgb':None, 'flow':None}\n",
    "feature_extract=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainable_params(model, mode='rgb'):\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "    optims[mode] = optim.SGD(model.parameters(), lr=1e-6, momentum=0.9, weight_decay=1e-7)\n",
    "\n",
    "trainable_params(i3d_rgb, 'rgb')\n",
    "trainable_params(i3d_flow, 'flow')\n",
    "    \n",
    "schedulers['rgb'] = MultiStepLR(optims['rgb'], milestones=[10], gamma=0.1)\n",
    "schedulers['flow'] = MultiStepLR(optims['flow'], milestones=[10], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(i3d_rgb, (3, 16, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train((i3d_rgb, i3d_flow), dataloaders, optims, criterion, schedulers, device, num_epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for label in ['clean', 'notclean']:\n",
    "    data_all = glob('./data/images/{}/*'.format(label))\n",
    "    data_train, data_test = train_test_split(data_all, test_size=0.1, random_state=42)\n",
    "    data_train, data_val = train_test_split(data_train, test_size=0.1, random_state=42)\n",
    "    data = {'train': data_train, 'val': data_val, 'test':data_test}\n",
    "    for phase in ['train', 'val', 'test']:\n",
    "        for path in data[phase]:\n",
    "            dst= './data/images/{}/{}'.format(phase, label)\n",
    "            !mv $path $dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "clean = {'train':[], 'val':[], 'test':[]}\n",
    "notclean = {'train':[], 'val':[], 'test':[]}\n",
    "clean_num = {'train':[], 'val':[], 'test':[]}\n",
    "notclean_num = {'train':[], 'val':[], 'test':[]}\n",
    "\n",
    "for phase in ['train', 'val', 'test']:\n",
    "    paths = [path for path in dataset[phase].samples[0] if len(os.path.basename(path).split('_')) == 3]\n",
    "    clean[phase] = [path for path in paths if '/clean/' in path]\n",
    "    notclean[phase] = [path for path in paths if '/notclean/' in path]\n",
    "for phase in ['train', 'val', 'test']:\n",
    "    for f in clean[phase]: \n",
    "        num = len(glob(os.path.join(f, '*.jpg')))\n",
    "        clean_num[phase].append(num)\n",
    "    for f in notclean[phase]: \n",
    "        num = len(glob(os.path.join(f, '*.jpg')))\n",
    "        notclean_num[phase].append(num)\n",
    "\n",
    "print('\\tclips', '\\timages', '\\tmin', '\\tmax')\n",
    "for key, value in clean_num.items():\n",
    "    print(key, '\\t%d\\t%d\\t%d\\t%d' % (len(value), sum(value), min(value), max(value)))\n",
    "print('\\tclips', '\\timages', '\\tmin', '\\tmax')\n",
    "for key, value in notclean_num.items():\n",
    "    print(key, '\\t%d\\t%d\\t%d\\t%d' % (len(value), sum(value), min(value), max(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def draw_result(lst_iter, lst_loss, lst_acc, title):\n",
    "    plt.plot(lst_iter, lst_loss, '-b', label='loss')\n",
    "    plt.plot(lst_iter, lst_acc, '-r', label='accuracy')\n",
    "\n",
    "    plt.xlabel(\"n iteration\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(title)\n",
    "\n",
    "    # save image\n",
    "    plt.savefig(title+\".png\")  # should before show method\n",
    "\n",
    "    # show\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_draw():\n",
    "    # iteration num\n",
    "    lst_iter = range(100)\n",
    "\n",
    "    # loss of iteration\n",
    "    lst_loss = [0.01 * i + 0.01 * i ** 2 for i in xrange(100)]\n",
    "    # lst_loss = np.random.randn(1, 100).reshape((100, ))\n",
    "\n",
    "    # accuracy of iteration\n",
    "    lst_acc = [0.01 * i - 0.01 * i ** 2 for i in xrange(100)]\n",
    "    # lst_acc = np.random.randn(1, 100).reshape((100, ))\n",
    "    draw_result(lst_iter, lst_loss, lst_acc, \"sgd_method\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
