{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, io, shutil\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "from dataloader.handhygiene import HandHygiene\n",
    "from spatial_transforms import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms import (\n",
    "    MirrorLoopPadding, LoopPadding, TemporalRandomCrop, \n",
    "    TemporalCenterCrop, TemporalRandomChoice)\n",
    "from openpose_transforms import CropTorso, MultiScaleTorsoRandomCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'i3d'\n",
    "img_size = 224\n",
    "crop_size = img_size\n",
    "batch_size = 4\n",
    "clip_len = 64\n",
    "num_classes = 1\n",
    "\n",
    "torch.manual_seed(100)\n",
    "data_name = 'anesthesia'\n",
    "dataset_path = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = 1.0\n",
    "sample_duration = 64\n",
    "sample_size = 224\n",
    "mean=[110.63666788, 103.16065604, 96.29023126]\n",
    "std=[38.7568578, 37.88248729, 40.02898126]\n",
    "\n",
    "scales=np.linspace(1, 1.75, num=4)\n",
    "openpose_transform = MultiScaleTorsoRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            Scale(sample_size),\n",
    "            CenterCrop(sample_size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(1), \n",
    "            Normalize(mean, std)])\n",
    "\n",
    "temporal_transform = TemporalRandomChoice([\n",
    "            LoopPadding(sample_duration),\n",
    "            MirrorLoopPadding(sample_duration),\n",
    "            TemporalRandomCrop(sample_duration),\n",
    "            TemporalCenterCrop(sample_duration)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of /data/private/minjee-video/handhygiene/data/images/train videos: 91\n",
      "Number of /data/private/minjee-video/handhygiene/data/images/val videos: 8\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    'train':HandHygiene(dataset_path, split='train', clip_len=clip_len, \n",
    "                        spatial_transform=spatial_transform,\n",
    "                        openpose_transform=openpose_transform,\n",
    "                        temporal_transform=temporal_transform, num_workers=16),\n",
    "    'val':HandHygiene(dataset_path, split='val', clip_len=clip_len, \n",
    "                        spatial_transform=spatial_transform,\n",
    "                        openpose_transform=openpose_transform,\n",
    "                        temporal_transform=temporal_transform, num_workers=16)}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(dataset['train'], batch_size=batch_size, shuffle=True, num_workers=16),\n",
    "    'val': DataLoader(dataset['val'], batch_size=batch_size, shuffle=False, num_workers=16)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_models\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "i3d_rgb, i3d_flow = get_models(num_classes, True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    i3d_rgb = nn.DataParallel(i3d_rgb)\n",
    "    i3d_flow = nn.DataParallel(i3d_flow)\n",
    "i3d_rgb.to(device)\n",
    "i3d_flow.to(device)\n",
    "\n",
    "criterion = F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t module.conv3d_0c_1x1.1.conv3d.weight\n",
      "\t module.conv3d_0c_1x1.1.conv3d.bias\n",
      "Params to learn:\n",
      "\t module.conv3d_0c_1x1.1.conv3d.weight\n",
      "\t module.conv3d_0c_1x1.1.conv3d.bias\n"
     ]
    }
   ],
   "source": [
    "optims={'rgb': None, 'flow':None}\n",
    "feature_extract=True\n",
    "            \n",
    "def trainable_params(model, mode='rgb'):\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "    optims[mode] = optim.SGD(model.parameters(), lr=1e-6, momentum=0.9, weight_decay=1e-7)\n",
    "    \n",
    "trainable_params(i3d_rgb, 'rgb')\n",
    "trainable_params(i3d_flow, 'flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal random crop\n",
      "mirror loop padding\n",
      "mirror loop padding\n",
      "loop padding\n",
      "mirror loop padding\n",
      "temporal random crop\n",
      "temporal random crop\n",
      "temporal random crop\n",
      "temporal center crop\n",
      "mirror loop padding\n",
      "temporal center crop\n",
      "temporal center crop\n",
      "mirror loop padding\n",
      "mirror loop padding\n",
      "loop padding\n",
      "temporal random crop\n",
      "1.75\n",
      "1.75\n",
      "1.75\n",
      "1.75\n",
      "1.5\n",
      "1.5\n",
      "1.5\n",
      "1.0\n",
      "1.75\n",
      "1.75\n",
      "1.5\n",
      "1.75\n",
      "1.5\n",
      "1.25\n",
      "1.75\n",
      "1.0\n",
      "temporal center crop\n",
      "temporal random crop\n",
      "mirror loop padding\n",
      "loop padding\n",
      "mirror loop padding\n",
      "temporal center crop\n",
      "loop padding\n",
      "mirror loop padding\n",
      "temporal random crop\n",
      "temporal center crop\n",
      "loop padding\n",
      "mirror loop padding\n",
      "mirror loop padding\n",
      "temporal random crop\n",
      "mirror loop padding\n",
      "temporal center crop\n",
      "1.0\n",
      "1.75\n",
      "1.25\n",
      "1.75\n",
      "1.0\n",
      "1.25\n",
      "1.25\n",
      "1.0\n",
      "1.75\n",
      "1.25\n",
      "1.25\n",
      "1.5\n",
      "1.25\n",
      "1.5\n",
      "1.75\n",
      "mirror loop padding\n",
      "1.25\n",
      "temporal center crop\n",
      "temporal center crop\n",
      "temporal center crop\n",
      "temporal center crop\n",
      "loop padding\n",
      "temporal center crop\n",
      "temporal random crop\n",
      "loop padding\n",
      "loop padding\n",
      "mirror loop padding\n",
      "mirror loop padding\n",
      "mirror loop padding\n",
      "temporal random crop\n",
      "temporal center crop\n",
      "loop padding\n"
     ]
    }
   ],
   "source": [
    "train((i3d_rgb, i3d_flow), dataloaders, optims, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
