{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "import argparse\n",
    "from IPython import embed #to debug\n",
    "import skvideo.io\n",
    "import scipy.misc\n",
    "\n",
    "\n",
    "def ToImg(raw_flow,bound):\n",
    "    '''\n",
    "    this function scale the input pixels to 0-255 with bi-bound\n",
    "    :param raw_flow: input raw pixel value (not in 0-255)\n",
    "    :param bound: upper and lower bound (-bound, bound)\n",
    "    :return: pixel value scale from 0 to 255\n",
    "    '''\n",
    "    flow=raw_flow\n",
    "    flow[flow>bound]=bound\n",
    "    flow[flow<-bound]=-bound\n",
    "    flow-=-bound\n",
    "    flow*=(255/float(2*bound))\n",
    "    return flow\n",
    "\n",
    "def save_flows(flows,image,save_dir,num,bound):\n",
    "    '''\n",
    "    To save the optical flow images and raw images\n",
    "    :param flows: contains flow_x and flow_y\n",
    "    :param image: raw image\n",
    "    :param save_dir: save_dir name (always equal to the video id)\n",
    "    :param num: the save id, which belongs one of the extracted frames\n",
    "    :param bound: set the bi-bound to flow images\n",
    "    :return: return 0\n",
    "    '''\n",
    "    #rescale to 0~255 with the bound setting\n",
    "    flow_x=ToImg(flows[...,0],bound)\n",
    "    flow_y=ToImg(flows[...,1],bound)\n",
    "    if not os.path.exists(os.path.join(data_root,new_dir,save_dir)):\n",
    "        os.makedirs(os.path.join(data_root,new_dir,save_dir))\n",
    "\n",
    "    #save the image\n",
    "    save_img=os.path.join(data_root,new_dir,save_dir,'img_{:05d}.jpg'.format(num))\n",
    "    scipy.misc.imsave(save_img,image)\n",
    "\n",
    "    #save the flows\n",
    "    save_x=os.path.join(data_root,new_dir,save_dir,'flow_x_{:05d}.jpg'.format(num))\n",
    "    save_y=os.path.join(data_root,new_dir,save_dir,'flow_y_{:05d}.jpg'.format(num))\n",
    "    flow_x_img=Image.fromarray(flow_x)\n",
    "    flow_y_img=Image.fromarray(flow_y)\n",
    "    scipy.misc.imsave(save_x,flow_x_img)\n",
    "    scipy.misc.imsave(save_y,flow_y_img)\n",
    "    return 0\n",
    "\n",
    "def dense_flow(augs):\n",
    "    '''\n",
    "    To extract dense_flow images\n",
    "    :param augs:the detailed augments:\n",
    "        video_name: the video name which is like: 'v_xxxxxxx',if different ,please have a modify.\n",
    "        save_dir: the destination path's final direction name.\n",
    "        step: num of frames between each two extracted frames\n",
    "        bound: bi-bound parameter\n",
    "    :return: no returns\n",
    "    '''\n",
    "    video_name,save_dir,step,bound=augs\n",
    "    video_path=os.path.join(videos_root,video_name.split('_')[1],video_name)\n",
    "\n",
    "    # provide two video-read methods: cv2.VideoCapture() and skvideo.io.vread(), both of which need ffmpeg support\n",
    "\n",
    "    # videocapture=cv2.VideoCapture(video_path)\n",
    "    # if not videocapture.isOpened():\n",
    "    #     print 'Could not initialize capturing! ', video_name\n",
    "    #     exit()\n",
    "    try:\n",
    "        videocapture=skvideo.io.vread(video_path)\n",
    "    except:\n",
    "        print '{} read error! '.format(video_name)\n",
    "        return 0\n",
    "    print video_name\n",
    "    # if extract nothing, exit!\n",
    "    if videocapture.sum()==0:\n",
    "        print 'Could not initialize capturing',video_name\n",
    "        exit()\n",
    "    len_frame=len(videocapture)\n",
    "    frame_num=0\n",
    "    image,prev_image,gray,prev_gray=None,None,None,None\n",
    "    num0=0\n",
    "    while True:\n",
    "        #frame=videocapture.read()\n",
    "        if num0>=len_frame:\n",
    "            break\n",
    "        frame=videocapture[num0]\n",
    "        num0+=1\n",
    "        if frame_num==0:\n",
    "            image=np.zeros_like(frame)\n",
    "            gray=np.zeros_like(frame)\n",
    "            prev_gray=np.zeros_like(frame)\n",
    "            prev_image=frame\n",
    "            prev_gray=cv2.cvtColor(prev_image,cv2.COLOR_RGB2GRAY)\n",
    "            frame_num+=1\n",
    "            # to pass the out of stepped frames\n",
    "            step_t=step\n",
    "            while step_t>1:\n",
    "                #frame=videocapture.read()\n",
    "                num0+=1\n",
    "                step_t-=1\n",
    "            continue\n",
    "\n",
    "        image=frame\n",
    "        gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "        frame_0=prev_gray\n",
    "        frame_1=gray\n",
    "        ##default choose the tvl1 algorithm\n",
    "        dtvl1=cv2.createOptFlow_DualTVL1()\n",
    "        flowDTVL1=dtvl1.calc(frame_0,frame_1,None)\n",
    "        save_flows(flowDTVL1,image,save_dir,frame_num,bound) #this is to save flows and img.\n",
    "        prev_gray=gray\n",
    "        prev_image=image\n",
    "        frame_num+=1\n",
    "        # to pass the out of stepped frames\n",
    "        step_t=step\n",
    "        while step_t>1:\n",
    "            #frame=videocapture.read()\n",
    "            num0+=1\n",
    "            step_t-=1\n",
    "\n",
    "\n",
    "def get_video_list():\n",
    "    video_list=[]\n",
    "    for cls_names in os.listdir(videos_root):\n",
    "        cls_path=os.path.join(videos_root,cls_names)\n",
    "        for video_ in os.listdir(cls_path):\n",
    "            video_list.append(video_)\n",
    "    video_list.sort()\n",
    "    return video_list,len(video_list)\n",
    "\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"densely extract the video frames and optical flows\")\n",
    "    parser.add_argument('--dataset',default='ucf101',type=str,help='set the dataset name, to find the data path')\n",
    "    parser.add_argument('--data_root',default='/n/zqj/video_classification/data',type=str)\n",
    "    parser.add_argument('--new_dir',default='flows',type=str)\n",
    "    parser.add_argument('--num_workers',default=4,type=int,help='num of workers to act multi-process')\n",
    "    parser.add_argument('--step',default=1,type=int,help='gap frames')\n",
    "    parser.add_argument('--bound',default=15,type=int,help='set the maximum of optical flow')\n",
    "    parser.add_argument('--s_',default=0,type=int,help='start id')\n",
    "    parser.add_argument('--e_',default=13320,type=int,help='end id')\n",
    "    parser.add_argument('--mode',default='run',type=str,help='set \\'run\\' if debug done, otherwise, set debug')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    # example: if the data path not setted from args,just manually set them as belows.\n",
    "    #dataset='ucf101'\n",
    "    #data_root='/S2/MI/zqj/video_classification/data'\n",
    "    #data_root=os.path.join(data_root,dataset)\n",
    "\n",
    "    args=parse_args()\n",
    "    data_root=os.path.join(args.data_root,args.dataset)\n",
    "    videos_root=os.path.join(data_root,'videos')\n",
    "\n",
    "    #specify the augments\n",
    "    num_workers=args.num_workers\n",
    "    step=args.step\n",
    "    bound=args.bound\n",
    "    s_=args.s_\n",
    "    e_=args.e_\n",
    "    new_dir=args.new_dir\n",
    "    mode=args.mode\n",
    "    #get video list\n",
    "    video_list,len_videos=get_video_list()\n",
    "    video_list=video_list[s_:e_]\n",
    "\n",
    "    len_videos=min(e_-s_,13320-s_) # if we choose the ucf101\n",
    "    print 'find {} videos.'.format(len_videos)\n",
    "    flows_dirs=[video.split('.')[0] for video in video_list]\n",
    "    print 'get videos list done! '\n",
    "\n",
    "    pool=Pool(num_workers)\n",
    "    if mode=='run':\n",
    "        pool.map(dense_flow,zip(video_list,flows_dirs,[step]*len(video_list),[bound]*len(video_list)))\n",
    "    else: #mode=='debug\n",
    "        dense_flow((video_list[0],flows_dirs[0],step,bound))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
